# Web-scraping-de-conflictos-sociolaborales
# ğŸ“° Observatorio de Conflictos Laborales â€” Santa Fe y Entre RÃ­os

El **Observatorio de Conflictos Laborales** es una herramienta automatizada de recolecciÃ³n, filtrado y clasificaciÃ³n de noticias relacionadas con **conflictos laborales, sindicales o gremiales** en las provincias de **Santa Fe** y **Entre RÃ­os (Argentina)**.

El sistema utiliza scraping semÃ¡ntico, anÃ¡lisis de coocurrencias y procesamiento bÃ¡sico de lenguaje natural (NLP) para identificar eventos laborales relevantes en medios locales, regionales y nacionales.

---

## ğŸ¯ Objetivos

- Relevar medios periodÃ­sticos locales y nacionales con foco en Santa Fe y Entre RÃ­os.  
- Detectar noticias relacionadas con **acciones colectivas de trabajadores**, **reclamos laborales** y **movilizaciones sindicales**.  
- Evitar temas no laborales mediante un diccionario de exclusiones (policiales, accidentes, etc.).  
- Clasificar los conflictos por **tipo de actor, acciÃ³n y territorio**.  
- Generar una base histÃ³rica limpia, actualizable y analizable.

---

## ğŸ§  MetodologÃ­a general

El proceso se organiza en tres etapas:

1. **ExtracciÃ³n y filtrado semÃ¡ntico (`scraping_er_sf.py`)**
   - Descarga titulares y textos de noticias mediante scraping y RSS.
   - Filtra por coocurrencia de *actores*, *acciones* y *reclamos*.
   - Identifica el *territorio* (Santa Fe o Entre RÃ­os) y calcula un *nivel de conflicto* (0â€“1).

2. **DepuraciÃ³n de duplicados (`deduplicador.py`)**
   - Combina los CSV de ambas provincias y elimina noticias repetidas o muy similares usando comparaciÃ³n textual (*RapidFuzz*).
   - Devuelve una base limpia (`conflictos_limpios.csv`).

3. **ClasificaciÃ³n temÃ¡tica (`clasificador_conflictos.py`)**
   - Clasifica los conflictos por *sector* (docente, salud, transporte, estatal, etc.).
   - Permite incorporar reglas o modelos NLP mÃ¡s complejos en futuras versiones.

---
```bash
ğŸ“‚ Estructura del repositorio

ğŸ“¦ ConflictoER/
â”œâ”€â”€ ğŸ“ data/ # Archivos CSV acumulativos
â”‚ â”œâ”€â”€ historico_santafe.csv
â”‚ â”œâ”€â”€ historico_entrerÃ­os.csv
â”‚ â””â”€â”€ historico_nacionales.csv
â”‚ â””â”€â”€ conflictos_limpios.csv
â”‚ â””â”€â”€ conflictos_clasificados.csv
â”œâ”€â”€ ğŸ“„ diccionario.json # Diccionario de tÃ©rminos laborales y geogrÃ¡ficos
â”œâ”€â”€ ğŸ§  scraping_er_sf.py # Script principal de scraping y filtrado semÃ¡ntico
â”œâ”€â”€ ğŸ§¹ deduplicador.py # Script de limpieza de duplicados
â””â”€â”€ ğŸ§¾ README.md # DocumentaciÃ³n del proyecto

```
---

# âš™ï¸ InstalaciÃ³n y configuraciÃ³n

## 1. Clonar el repositorio
```bash
git clone https://github.com/<tu_usuario>/ConflictoER.git
cd ConflictoER
```

## **2. Crear un entorno virtual (opcional)**
```bash
python -m venv venv
source venv/bin/activate      # Linux/macOS
venv\Scripts\activate         # Windows
```

## **3. Instalar dependencias**
```bash
pip install requests beautifulsoup4 feedparser pandas rapidfuzz
```
----

# **ğŸš€ EjecuciÃ³n paso a paso**

## 1ï¸âƒ£ Relevar noticias
*python scraping_er_sf.py*

ğŸ“¥ Este script:
Extrae noticias de medios locales y nacionales.
Filtra por coocurrencias (actores + acciones + reclamos).
Detecta provincia o localidad.
Calcula nivel de conflicto (nivel_conflicto entre 0 y 1).

*Salidas:*
data/historico_santafe.csv
data/historico_entrerÃ­os.csv
data/historico_nacionales.csv


## 2ï¸âƒ£ Eliminar duplicados
*python deduplicador.py*

ğŸ§¹ Este script:
Combina los CSV anteriores.
Elimina duplicados exactos y por similitud (>90%).

*Devuelve una base consolidada y limpia:*
data/conflictos_limpios.csv


## **3ï¸âƒ£ Clasificar los conflictos**
*python clasificador_conflictos.py*

*ğŸ§  Este script:*
Clasifica los conflictos por tipo de sector laboral.
Agrega las columnas:
- categoria_conflicto
- fecha_clasificacion
- subnivel_conflicto (opcional: bajo / medio / alto)

*Salida:*
data/conflictos_clasificados.csv

---

```bash
ğŸ“Š Campos del dataset final

**Campo**	             	 â”‚  **DescripciÃ³n**
fecha_relevamiento	     	 â”‚  Fecha del scraping
medio	                 	 â”‚  Fuente periodÃ­stica
titulo	                 	 â”‚  TÃ­tulo original
link	                 	 â”‚  URL del artÃ­culo
texto	                  	 â”‚  Cuerpo de la noticia
territorio	              	 â”‚  Santa Fe / Entre RÃ­os
acciones_detectadas	         â”‚  Palabras clave de acciÃ³n
actores_detectados           â”‚  Palabras clave de actor
reclamos_detectados	      	 â”‚  Palabras clave de reclamo
verbos_detectados	         â”‚  Verbos asociados a conflictos
repertorios_detectados	     â”‚  Formas de acciÃ³n colectiva
instituciones_detectadas	 â”‚  Menciones a organismos
nivel_conflicto	             â”‚  Valor 0â€“1 segÃºn coocurrencias
coocurrencia	             â”‚  Estructura A:B:C detectada
categoria_conflicto          â”‚	ClasificaciÃ³n temÃ¡tica (docente, salud, etc.)
subnivel_conflicto	         â”‚  Bajo / Medio / Alto (segÃºn puntaje)
longitud_texto	             â”‚  Longitud del texto analizado

---
	
ğŸ—ï¸ Medios relevados

*ğŸŸ¦ Entre RÃ­os*
AnÃ¡lisis Digital
El MiÃ©rcoles Digital
El Heraldo de Concordia (RSS)
El DÃ­a de GualeguaychÃº (RSS)
La Calle (ConcepciÃ³n del Uruguay)
AIM Digital
APF Digital

*ğŸŸ¥ Santa Fe*
Aire de Santa Fe
Santa Fe Noticias
Pausa (Santa Fe)
Diario Castellanos (Rafaela)
Esperanza DÃ­a x DÃ­a
Reconquista Hoy

*âšª Nacionales (con cobertura regional)*
InfoGremiales
La Izquierda Diario (Entre RÃ­os)
La Izquierda Diario (Santa Fe)

---

ğŸ§© Flujo de trabajo completo

*scraping_er_sf.py*           â†’ RecolecciÃ³n y filtrado semÃ¡ntico
*deduplicador.py*             â†’ Limpieza de duplicados
*clasificador_conflictos.py*  â†’ ClasificaciÃ³n temÃ¡tica por sector

*Resultado final:*
data/conflictos_clasificados.csv

```
---

## âš ï¸ Nota importante sobre el scraping de medios 

El funcionamiento correcto de los scripts de scraping depende directamente de la **estructura HTML de cada sitio web** (etiquetas, clases, identificadores, jerarquÃ­a del DOM). Dado que **cada medio utiliza un diseÃ±o distinto** â€”y que estos pueden modificarse con el tiempoâ€”, es necesario **verificar previamente la estructura de las pÃ¡ginas** antes de ejecutar o adaptar el cÃ³digo.
Si un medio cambia su maquetaciÃ³n (por ejemplo, los nombres de las clases CSS o la forma en que se renderiza el contenido), el script puede dejar de capturar correctamente tÃ­tulos, fechas o cuerpos de texto.

### RecomendaciÃ³n prÃ¡ctica
Ante fallas o al incorporar nuevos medios:
1. Abrir una noticia del medio en el navegador.
2. Inspeccionar el HTML (clic derecho â†’ *Inspeccionar*).
3. Copiar los fragmentos relevantes del cÃ³digo (contenedores de tÃ­tulo, fecha y texto).
4. Compartir esa estructura con una herramienta de asistencia (por ejemplo, ChatGPT) para identificar con mayor precisiÃ³n:
   - etiquetas (`div`, `article`, `h1`, `p`, etc.),
   - clases o identificadores,
   - y los selectores adecuados a utilizar en el scraping.
Esta verificaciÃ³n previa permite **ajustar los selectores del script** y garantizar una extracciÃ³n de datos consistente y reproducible.

---

## **ğŸ§° Posibles mejoras futuras**
Incorporar embeddings o modelos de clasificaciÃ³n supervisada (BERT, DistilBERT, SBERT).
Analizar frecuencia temporal y territorial de conflictos (dashboards).
DetecciÃ³n automÃ¡tica de gremios y empresas involucradas.
Enlace con datasets comparativos: Mass Mobilization (Harvard) o ACEP (Nieto, UNMdP).
Agregar capa de visualizaciÃ³n (Streamlit / Power BI).

---
## ğŸ“– **CrÃ©ditos**
Autor: *Camila Barreto*  â”‚
Proyecto: Observatorio de Conflictos Laborales â€” Entre RÃ­os / Santa Fe  â”‚
ColaboraciÃ³n tÃ©cnica: GPT-5.2 (OpenAI, 2025)

