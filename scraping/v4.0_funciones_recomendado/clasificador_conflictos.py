# clasipip installficador_conflictos_v4.py ‚Äî NLP + reglas
# Clasificaci√≥n sem√°ntica y territorial de conflictos laborales

import pandas as pd
from pathlib import Path
import json
import re
import spacy

# ----------------------------
# CONFIGURACI√ìN
# ----------------------------
DATA_PATH = Path("data/Bases de datos originales/")
archivos_fuente = [DATA_PATH / "conflictos_limpios.csv"]
salida = DATA_PATH / "conflictos_clasificados_nlp.csv"

# Carga modelo spaCy espa√±ol
print("üß† Cargando modelo de lenguaje spaCy (es_core_news_md)...")
nlp = spacy.load("es_core_news_md")

# ----------------------------
# DICCIONARIOS (como versi√≥n 3.0)
# ----------------------------
TIPOS_CONFLICTO = {
    "Reivindicativo": [
        "reclamo", "reclaman", "exigen", "pedido", "petitorio", "demanda", "aumento", "paritaria",
        "incremento", "recomposici√≥n", "revisi√≥n salarial", "mejora salarial", "convenio colectivo",
        "mejoras en las condiciones", "regularizaci√≥n", "bono", "equiparaci√≥n"
    ],
    "Defensivo": [
        "despido", "cesante", "cesant√≠as", "suspensi√≥n", "lockout", "crisis", "recorte", "cierre",
        "retiro voluntario", "liquidaci√≥n", "atraso salarial", "falta de pago", "reducci√≥n"
    ],
    "Institucional": [
        "ministerio", "intendencia", "municipio", "funcionario", "autoridad", "gobernador", "secretar√≠a",
        "ministro", "consejo", "gobierno", "paritaria provincial"
    ],
    "Pol√≠tico-solidario": [
        "reforma laboral", "protesta nacional", "ajuste del gobierno", "ley", "pol√≠tica nacional",
        "represi√≥n", "crisis econ√≥mica", "solidaridad"
    ],
    "Sindical interno": [
        "asamblea", "delegados", "comisi√≥n directiva", "elecci√≥n sindical", "internas gremiales",
        "disputa gremial", "cambio de conducci√≥n", "renovaci√≥n autoridades"
    ],
    "Laboral general": [
        "trabajador", "trabajadores", "empleado", "empleados", "paro", "huelga", "manifestaci√≥n", "piquete"
    ],
}

SECTORES = {
    "educaci√≥n": ["docente", "maestro", "profesor", "universidad", "facultad", "escuela", "amafe", "amsafe"],
    "salud": ["hospital", "m√©dico", "enfermero", "sanatorio", "cl√≠nica", "salud p√∫blica"],
    "transporte": ["chofer", "colectivo", "transporte", "camionero", "uta", "taxista", "ferroviario"],
    "industria": ["f√°brica", "metal√∫rgico", "planta", "obreros", "industrial", "smata", "uom"],
    "estatales": ["ate", "upcn", "empleado p√∫blico", "ministerio", "provincia"],
    "municipales": ["municipal", "intendencia", "empleados municipales", "obrador"],
    "bancarios": ["banco", "bancario", "la bancaria"],
    "rurales": ["campo", "pe√≥n", "uatre", "agro", "tractor"],
    "comercio": ["empleado de comercio", "supermercado", "vendedor", "shopping"],
    "servicios": ["telefon√≠a", "energ√≠a", "gas", "agua", "obra social", "electricista"],
    "seguridad": ["polic√≠a", "penitenciario", "guardia", "bombero"]
}

TERRITORIOS = {
    "Santa Fe": [
        "santa fe", "rafaela", "reconquista", "esperanza", "venado tuerto", "santa fe capital",
        "san lorenzo", "casilda", "galvez", "ceres", "sunchales", "ca√±ada de g√≥mez", "coronda"
    ],
    "Entre R√≠os": [
        "paran√°", "concordia", "gualeguaych√∫", "concepci√≥n del uruguay",
        "villaguay", "nogoy√°", "victoria", "col√≥n", "gualeguay", "diamante", "feliciano", "san jos√©", "villa elisa", "ubajay", "oro verde", "santa ana", "liebig", "rosario del tala", "basavilbaso", "concordia"
    ],
}

# ----------------------------
# FUNCIONES AUXILIARES
# ----------------------------
def normalizar_texto(txt):
    txt = str(txt).lower()
    txt = re.sub(r"[^a-z√°√©√≠√≥√∫√º√±0-9\s]", " ", txt)
    txt = re.sub(r"\s+", " ", txt).strip()
    return txt

def clasificar_tipo_conflicto(texto):
    texto = normalizar_texto(texto)
    for tipo, palabras in TIPOS_CONFLICTO.items():
        if any(p in texto for p in palabras):
            return tipo
    return "Indeterminado"

def clasificar_sector(texto):
    texto = normalizar_texto(texto)
    for sector, terminos in SECTORES.items():
        if any(t in texto for t in terminos):
            return sector
    return "general"

def detectar_territorio_y_localidad(texto, medio):
    texto_lower = normalizar_texto(texto)
    medio_lower = normalizar_texto(medio)

    # 1Ô∏è‚É£ Buscar localidad expl√≠cita
    for provincia, localidades in TERRITORIOS.items():
        for loc in localidades:
            if re.search(rf"\b{re.escape(loc)}\b", texto_lower):
                return provincia, loc.capitalize()

    # 2Ô∏è‚É£ Inferencia por medio
    if "santa fe" in medio_lower or "rosario" in medio_lower:
        return "Santa Fe", "no se menciona localidad"
    if "r√≠os" in medio_lower or "entrerios" in medio_lower or "paran√°" in medio_lower:
        return "Entre R√≠os", "no se menciona localidad"

    return "no identificado", "no se menciona localidad"

def analizar_nlp(texto):
    """Usa spaCy para extraer entidades y posibles actores laborales/geogr√°ficos."""
    doc = nlp(texto)
    entidades = [ent.text for ent in doc.ents]
    actores = [ent.text for ent in doc.ents if ent.label_ in ("ORG", "PER")]

    # Detectar si hay entidades geogr√°ficas no reconocidas por reglas
    geos = [ent.text for ent in doc.ents if ent.label_ in ("LOC", "GPE")]

    return {
        "entidades_detectadas": ", ".join(set(entidades)),
        "actores_nlp": ", ".join(set(actores)),
        "geos_detectadas": ", ".join(set(geos))
    }

# ----------------------------
# PROCESAMIENTO PRINCIPAL
# ----------------------------
def procesar_datasets():
    df_total = []

    for archivo in archivos_fuente:
        if not archivo.exists():
            print(f"‚ö†Ô∏è No se encontr√≥ {archivo}")
            continue

        df = pd.read_csv(archivo)
        if df.empty:
            continue

        print(f"üìÑ Procesando {archivo.name} ({len(df)} filas)")
        df["uid"] = df.apply(lambda x: hash((str(x.get("titulo", "")).lower().strip() + str(x.get("medio", "")).lower().strip())), axis=1)

        df["tipo_conflicto"] = df["texto"].fillna("").apply(clasificar_tipo_conflicto)
        df["sector"] = df["texto"].fillna("").apply(clasificar_sector)

        territorios_localidades = df.apply(lambda x: detectar_territorio_y_localidad(str(x.get("texto", "")), x.get("medio", "")), axis=1)
        df["territorio"] = territorios_localidades.apply(lambda t: t[0])
        df["localidad"] = territorios_localidades.apply(lambda t: t[1])

        # üîç NLP enrichment
        nlp_resultados = df["texto"].fillna("").apply(analizar_nlp)
        df["entidades_detectadas"] = nlp_resultados.apply(lambda d: d["entidades_detectadas"])
        df["actores_nlp"] = nlp_resultados.apply(lambda d: d["actores_nlp"])
        df["geos_detectadas"] = nlp_resultados.apply(lambda d: d["geos_detectadas"])

        df_total.append(df)

    if not df_total:
        print("‚ö†Ô∏è No hay datos para procesar.")
        return

    df_final = pd.concat(df_total, ignore_index=True)

    if salida.exists():
        df_existente = pd.read_csv(salida)
        if "uid" not in df_existente.columns:
            df_existente["uid"] = df_existente.apply(lambda x: hash((str(x.get("titulo", "")).lower().strip() + str(x.get("medio", "")).lower().strip())), axis=1)
    else:
        df_existente = pd.DataFrame(columns=df_final.columns)

    uids_existentes = set(df_existente["uid"].tolist())
    nuevos = df_final[~df_final["uid"].isin(uids_existentes)]
    df_actualizado = pd.concat([df_existente, nuevos], ignore_index=True)
    df_actualizado.to_csv(salida, index=False, encoding="utf-8-sig")

    print(f"‚úÖ Dataset actualizado: {len(nuevos)} nuevas noticias agregadas ({len(df_actualizado)} totales).")
    print("\n=== Distribuci√≥n por tipo de conflicto ===")
    print(df_actualizado["tipo_conflicto"].value_counts().to_string())
    print("\n=== Distribuci√≥n por sector ===")
    print(df_actualizado["sector"].value_counts().to_string())
    print("\n=== Distribuci√≥n por territorio ===")
    print(df_actualizado["territorio"].value_counts().to_string())


# ----------------------------
# MAIN
# ----------------------------
if __name__ == "__main__":
    procesar_datasets()

